{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before submitting\n",
    "1. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel\\Restart) and then **run all cells** (in the menubar, select Cell\\Run All).\n",
    "\n",
    "2. Make sure that no assertions fail or exceptions occur, otherwise points will be subtracted.\\n\",\n",
    "\n",
    "3. After you submit the notebook more tests will be run on your code. The fact that no assertions fail on your computer localy does not guarantee that completed the exercise correctly.\n",
    "\n",
    "4. Please submit only the `*.ipynb` file.\n",
    "\n",
    "5. Make sure you fill in any place that says `YOUR CODE HERE` or \\\"YOUR ANSWER HERE\\\". Edit only between `YOUR CODE HERE` and `END YOUR CODE`.\n",
    "\n",
    "6. Make sure to use Python 3.6 at least."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.version_info < (3, 6):\n",
    "    print(\"You are not using a modern enough version of Python. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a9990d4e2a04f3537d8b3d837155c47",
     "grade": false,
     "grade_id": "cell-8c6240920f08e7c8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Sheet 5: Rounding, Overflow, Linear Algebra\n",
    "\n",
    "In this exercise sheet, we look at various sources of numerical overflow when executing Python and numpy code for large input values, and how to efficiently handle them, for example, by using numpy special functions. There are other packages (e.g. `Decimal`) that can handle arbitrary precicion but they are very slow so we tend not to use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c799a9abbe26d558f99f495d8a18e8dc",
     "grade": true,
     "grade_id": "cell-fb7f2038e4baf8c8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import itertools\n",
    "import unittest\n",
    "\n",
    "t = unittest.TestCase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17554158a65f4682d10c806d87941b08",
     "grade": false,
     "grade_id": "cell-7b83d2a6a8025963",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Building a robust \"softplus\" nonlinear function (30 P)\n",
    "\n",
    "The softplus function is defined as:\n",
    "\n",
    "$$\n",
    "\\mathrm{softplus}(x) = \\log(1+\\exp(x)).\n",
    "$$\n",
    "\n",
    "It intervenes as elementary computation in certain machine learning models such as neural networks. Plotting it gives the following curve\n",
    "\n",
    "![plot generated wit desmos](softplus.png)\n",
    "\n",
    "where the function tends to **zero** for very negative input values and tends to the **identity** for very positive input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6b63e69b46195e21a941171695a6f19",
     "grade": false,
     "grade_id": "cell-b4a5e79e5bed3060",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def softplus(z):\n",
    "    return np.log(1 + np.exp(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider an input vector from the module `utils` containing varying values between 1 and 10000. We would like to apply the `softplus` function to all of its element in an element-wise manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "551c646afe97e8ec607f5bb23dff82ec",
     "grade": false,
     "grade_id": "cell-b95b2b454d4f3a00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10000, -1000, -100, -10, -1, 0, 1, 10, 100, 1000, 10000]\n"
     ]
    }
   ],
   "source": [
    "X = utils.softplus_inputs\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose these large values in order to test whether the behavior of the function is correct in all regimes of the function, in particular, for very small or very large values. The code below applies the `softplus` function directly to the vector of inputs and then prints for all cases the input and the corresponding function output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "793b674a8254f9f58e92be636580f459",
     "grade": false,
     "grade_id": "cell-bf597d846e14f0cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softplus(-10000.0000) =      0.0000\n",
      "softplus( -1000.0000) =      0.0000\n",
      "softplus(  -100.0000) =      0.0000\n",
      "softplus(   -10.0000) =      0.0000\n",
      "softplus(    -1.0000) =      0.3133\n",
      "softplus(     0.0000) =      0.6931\n",
      "softplus(     1.0000) =      1.3133\n",
      "softplus(    10.0000) =     10.0000\n",
      "softplus(   100.0000) =    100.0000\n",
      "softplus(  1000.0000) =         inf\n",
      "softplus( 10000.0000) =         inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-65fe6e33a0df>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log(1 + np.exp(z))\n"
     ]
    }
   ],
   "source": [
    "Y = softplus(X)\n",
    "for x, y in zip(X, Y):\n",
    "    print(f\"softplus({x:11.4f}) = {y:11.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large input values, the softplus function returns `inf` whereas analysis of that function tells us that it should compute the **identity**. Let's now try to apply the softplus function one element at a time, to see whether the problem comes from numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cff21156c3dffbd3d6a0fdf54d3dbfe0",
     "grade": false,
     "grade_id": "cell-6b58a18af5f12412",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softplus(-10000.0000) =      0.0000\n",
      "softplus( -1000.0000) =      0.0000\n",
      "softplus(  -100.0000) =      0.0000\n",
      "softplus(   -10.0000) =      0.0000\n",
      "softplus(    -1.0000) =      0.3133\n",
      "softplus(     0.0000) =      0.6931\n",
      "softplus(     1.0000) =      1.3133\n",
      "softplus(    10.0000) =     10.0000\n",
      "softplus(   100.0000) =    100.0000\n",
      "softplus(  1000.0000) =         inf\n",
      "softplus( 10000.0000) =         inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-65fe6e33a0df>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log(1 + np.exp(z))\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    y = softplus(x)\n",
    "    print(f\"softplus({x:11.4f}) = {y:11.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the result is the same. We observe that the function always stops working when its output approaches 1000, even though the input was given in high precision `float64`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create an alternative function for `softplus_robust` that applies to input scalars (int, float, etc.) and that correctly applies to values that can be much larger than 1000 (e.g. billions or more). Your function can be written in Python directly and does not need numpy parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e75b11ce107affd9148bfde1064bb0c",
     "grade": false,
     "grade_id": "cell-93b1547259c034bf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def softplus_robust(\n",
    "    x: Union[float, np.float32, np.float64]\n",
    ") -> Union[float, np.float32, np.float64]:\n",
    "    \"\"\"\n",
    "    Numerically stable implementation of softplus function. Will never \n",
    "    overflow to infinity if input is finite\n",
    "    \n",
    "    Args:\n",
    "        x (Union[float, np.float32, np.float64]): The number of which we \n",
    "        want to calculate the softplus value\n",
    "    Returns:\n",
    "        Union[float, np.float32, np.float64]: softplus(x)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if x>100:\n",
    "        return x\n",
    "    else:\n",
    "        return softplus(x)\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa3d038663588182392b2508b113f9fa",
     "grade": true,
     "grade_id": "cell-fb74b76bf3187fe1",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softplus(-10000.0000) =      0.0000\n",
      "softplus( -1000.0000) =      0.0000\n",
      "softplus(  -100.0000) =      0.0000\n",
      "softplus(   -10.0000) =      0.0000\n",
      "softplus(    -1.0000) =      0.3133\n",
      "softplus(     0.0000) =      0.6931\n",
      "softplus(     1.0000) =      1.3133\n",
      "softplus(    10.0000) =     10.0000\n",
      "softplus(   100.0000) =    100.0000\n",
      "softplus(  1000.0000) =   1000.0000\n",
      "softplus( 10000.0000) =  10000.0000\n"
     ]
    }
   ],
   "source": [
    "# Verify your function\n",
    "y_scalar = [softplus_robust(x) for x in X]\n",
    "\n",
    "for x, y in zip(X, y_scalar):\n",
    "    print(\"softplus(%11.4f) = %11.4f\" % (x, y))\n",
    "\n",
    "# the elements can be any of the three\n",
    "t.assertIsInstance(y_scalar[0], (float, np.float32, np.float64))\n",
    "t.assertAlmostEqual(softplus_robust(100000), 100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "608865528832fb31bb2e0ad3081da57e",
     "grade": true,
     "grade_id": "cell-50572c3826ea36f0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. Do not delete it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "564eb1615b077eac8471a62ccd61533f",
     "grade": false,
     "grade_id": "cell-c47d1d41d1970a7d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def softplus_robust_vec(X: \"vector-like\"):\n",
    "    \"\"\"\n",
    "    Vectorized version of the numericaly robust softplus function\n",
    "    \n",
    "    Args:\n",
    "        X (vector-like): A vector (ndim=1) of values on which we want to apply the softplus function.\n",
    "            It is not always a np.ndarray\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A vector (ndim=1) where the ret[i] == softplus_robust(X[i])\n",
    "    \"\"\"\n",
    "    # these are wrong!!!\n",
    "    # return np.array([softplus_robust(x) for x in X])\n",
    "    # return np.array(list(map(softplus_robust, X)))\n",
    "    # return np.vectorize(softplus_robust)(X)\n",
    "    # etc...\n",
    "    # YOUR CODE HERE\n",
    "    X = np.asarray(X, dtype=np.float)\n",
    "    #return np.where(X>100,X,softplus(X))\n",
    "    small_idx = np.less(X, 100)\n",
    "    X = X[small_idx]\n",
    "    return X\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91826a04256ec930bfdb6e7da1883184",
     "grade": true,
     "grade_id": "cell-cfd426eaca3d5169",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softplus(-10000.0000) = -10000.0000\n",
      "softplus( -1000.0000) =  -1000.0000\n",
      "softplus(  -100.0000) =   -100.0000\n",
      "softplus(   -10.0000) =    -10.0000\n",
      "softplus(    -1.0000) =     -1.0000\n",
      "softplus(     0.0000) =      0.0000\n",
      "softplus(     1.0000) =      1.0000\n",
      "softplus(    10.0000) =     10.0000\n",
      "Vectorized function needs...\n",
      "The slowest run took 4.60 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "288 µs ± 185 µs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "Python loops need...\n",
      "104 ms ± 39.5 µs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Verify your function\n",
    "Y = softplus_robust_vec(X)\n",
    "t.assertIsInstance(Y, np.ndarray)\n",
    "t.assertEqual(Y.dtype, np.float)\n",
    "pairs = tuple(zip(X, Y))\n",
    "for tup in pairs:\n",
    "    print(\"softplus(%11.4f) = %11.4f\" % tup)\n",
    "\n",
    "\"\"\"\n",
    "This is just a demonstration.\n",
    "As long as your vectorized function is consistently faster than the loop implementation,\n",
    "your solution should be acceptable. \n",
    "There are no concrete numbers about the speed-up, but as a reference\n",
    "on our machine the vectorized code needs < 1ms and the one using a loop\n",
    "requires > 100ms\n",
    "\"\"\"\n",
    "RAND_INPUT = np.random.rand(20000)\n",
    "print(\"Vectorized function needs...\")\n",
    "%timeit -r2 -n5 softplus_robust_vec(RAND_INPUT)\n",
    "\n",
    "\n",
    "def vectorize_with_loop(X):\n",
    "    # This is a wrong implementation\n",
    "    return np.array([softplus_robust(x) for x in X])\n",
    "\n",
    "\n",
    "print(\"Python loops need...\")\n",
    "%timeit -r2 -n5 vectorize_with_loop(RAND_INPUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing a partition function (40 P)\n",
    "\n",
    "We consider a discrete probability distribution of type\n",
    "$$\n",
    "p(\\boldsymbol{x};\\boldsymbol{w}) = \\frac{1}{Z(\\boldsymbol{w})} \\exp(\\boldsymbol{x}^\\top \\boldsymbol{w})\n",
    "$$\n",
    "where $\\boldsymbol{x} \\in \\{-1,1\\}^{10}$ is an observation, and $\\boldsymbol{w} \\in \\mathbb{R}^{10}$ is a vector of parameters. The term $Z(\\boldsymbol{w})$ is called the partition function and is chosen such that the probability distribution sums to 1. That is, the equation:\n",
    "$$\n",
    "\\sum_{\\boldsymbol{x} \\in \\{-1,1\\}^{10}} p(\\boldsymbol{x};\\boldsymbol{w}) = 1\n",
    "$$\n",
    "must be satisfied. Below is a simple method that computes the log of the partition function $Z(\\boldsymbol{w})$ for various choices of parameter vectors. The considered parameters (`w_small`, `w_medium`, and `w_large`) are increasingly large (and thus problematic), and can be found in the file `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    17.2457\n",
      "    89.5932\n",
      "        inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-1357455383ca>:21: RuntimeWarning: overflow encountered in exp\n",
      "  Z = sum(np.exp(np.dot(x, w)) for x in generate_all_observations())\n"
     ]
    }
   ],
   "source": [
    "def generate_all_observations():\n",
    "    \"\"\"\n",
    "    All x in { -1,1 }^10 (vectors with 10 elements where each element \n",
    "    containts either -1 or 1)\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray : All valid obvervations\n",
    "    \"\"\"\n",
    "    return np.array(tuple(itertools.product([-1, 1], repeat=10)))\n",
    "\n",
    "\n",
    "def getlogZ(w: 'vector-like'):\n",
    "    \"\"\"\n",
    "    Calculates the log of the partition function Z\n",
    "    \n",
    "    Args:\n",
    "        w (vector-like): A ten element vector (shape=(10,)) of parameters\n",
    "    Returns:\n",
    "        number: The log of the partition function Z\n",
    "    \"\"\"\n",
    "    Z = sum(np.exp(np.dot(x, w)) for x in generate_all_observations())\n",
    "    return np.log(Z)\n",
    "\n",
    "\n",
    "print(f\"{getlogZ(utils.w_small):11.4f}\")\n",
    "print(f\"{getlogZ(utils.w_medium):11.4f}\")\n",
    "print(f\"{getlogZ(utils.w_big):11.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from these results, that for parameter vectors with large values (e.g. `utils.w_big`), the exponential function overflows, and thus, we do not obtain a correct value for the logarithm of `Z`.\n",
    "\n",
    "* Implement an improved function  `getlogZ_robust` that avoids the overflow problem, and evaluates the partition function for the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38215cdec4cc4e379d6d58ed9ae066ca",
     "grade": false,
     "grade_id": "cell-00f9c42442638723",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def getlogZ_robust(w):\n",
    "    # YOUR CODE HERE\n",
    "    X = generate_all_observations()\n",
    "    maks = np.amax(np.dot(X,w))\n",
    "    Z = sum(np.exp(np.dot(x, w) - maks) for x in X)\n",
    "    return (maks + np.log(Z))\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc92228e5a7b3f2825320661238a5368",
     "grade": true,
     "grade_id": "cell-4a28c4a0b78d1e03",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    17.2457\n",
      "    89.5932\n",
      " 24919.9913\n"
     ]
    }
   ],
   "source": [
    "# Verify your function\n",
    "print(f\"{getlogZ_robust(utils.w_small):11.4f}\")\n",
    "print(f\"{getlogZ_robust(utils.w_medium):11.4f}\")\n",
    "print(f\"{getlogZ_robust(utils.w_big):11.4f}\")\n",
    "\n",
    "R = getlogZ_robust(utils.w_big)\n",
    "t.assertTrue(np.isfinite(R))\n",
    "t.assertTrue(24919 < R < 24920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4bd81eec5a000bb16f60857157a62b",
     "grade": true,
     "grade_id": "cell-19f26afe8bb83be6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. Do not delete it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For the model with parameter `utils.w_big`, evaluate the log-probability of the binary vectors generated by `generate_all_observations`, and return a `np.ndarray` of the indices (starting from 0) of those that have **probability** greater or equal to 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f06acd43be1776c194cbfc3def53ba9f",
     "grade": false,
     "grade_id": "cell-f2f50a11749c5d3e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def important_indexes(tol=0.001) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the indexes of important binary vectors for the w_big \n",
    "    parameter vector.\n",
    "    \n",
    "    Args:\n",
    "        tol (float): The probability threshhold\n",
    "        \n",
    "    Returns:\n",
    "        (np.ndarray): The indexes where the probability is greter or equal\n",
    "        to `tol`\n",
    "    \"\"\"\n",
    "    logZ = getlogZ_robust(utils.w_big)\n",
    "    # YOUR CODE HERE\n",
    "    X = generate_all_observations()\n",
    "    #logp = log(1/Z(w) * exp(xTw)) = log(1/Z(w))+ log(exp(xTw)) = -log(Z(W))+xTw\n",
    "    \n",
    "                    # burda log un expi kendisine esit o yüzden bi altta exp almadik\n",
    "    logp = -logZ + np.dot(X, utils.w_big) \n",
    "    \n",
    "    #logdan kurtulmak icin exponent aldik\n",
    "    p = np.exp(logp)\n",
    "    \n",
    "    ind = np.where(p>= tol)\n",
    "    return ind[0]\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdeee230016a5c89f6d60785e3ba0a68",
     "grade": true,
     "grade_id": "cell-89878affaff6ee2e",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Verify your function\n",
    "imp_idxs = important_indexes()\n",
    "print(f\"important indexes -> {imp_idxs}\")\n",
    "t.assertEqual(len(imp_idxs), 24)\n",
    "t.assertEqual(imp_idxs.dtype, int)\n",
    "t.assertEqual(imp_idxs[0], 81)\n",
    "t.assertEqual(imp_idxs[-1], 983)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of generating data from a Gaussian model (30 P)\n",
    "\n",
    "Consider a multivariate Gaussian distribution of mean vector `m` and covariance `S`. The probability associated to a vector `x` is given by:\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{x};(\\boldsymbol{m},S)) = \\frac{1}{\\sqrt{(2\\pi)^d \\mathrm{det}(S)}} \\exp \\Big( - \\frac12 (\\boldsymbol{x}-\\boldsymbol{m})^\\top S^{-1} (\\boldsymbol{x}-\\boldsymbol{m})\\Big)\n",
    "$$\n",
    "\n",
    "We consider the calculation of the probability of observing a certain dataset \n",
    "\n",
    "$$\n",
    "\\mathcal{D} = (\\boldsymbol{x}^{(1)},\\dots,\\boldsymbol{x}^{(N)})\n",
    "$$\n",
    "\n",
    "assuming the data is generated according to a Gaussian distribution of fixed parameters $\\boldsymbol{m}$ and $S$. Such probability density is given by the formula:\n",
    "\n",
    "$$\n",
    "\\log P(\\mathcal{D};(\\boldsymbol{m},S)) = \\log \\prod_{i=1}^N p(\\boldsymbol{x}^{(i)};(\\boldsymbol{m},S))\n",
    "$$\n",
    "\n",
    "The function below implements such function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58a6c59faacb2744c4d18f32ce4f795d",
     "grade": false,
     "grade_id": "cell-880ff6186ea830d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def logp(X, m, S):\n",
    "    # Find the number of dimensions from the data vector\n",
    "    d = X.shape[1]\n",
    "\n",
    "    # Invert the covariance matrix\n",
    "    Sinv = np.linalg.inv(S)\n",
    "\n",
    "    # Compute the quadratic terms for all data points\n",
    "    Q = -0.5 * (np.dot(X - m, Sinv) * (X - m)).sum(axis=1)\n",
    "\n",
    "    # Raise them quadratic terms to the exponential\n",
    "    Q = np.exp(Q)\n",
    "\n",
    "    # Divide by the terms in the denominator\n",
    "    P = Q / np.sqrt((2 * np.pi) ** d * np.linalg.det(S))\n",
    "\n",
    "    # Take the product of the probability of each data points\n",
    "    Pprod = np.prod(P)\n",
    "\n",
    "    # Return the log-probability\n",
    "    return np.log(Pprod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of this function for various datasets and parameters provided in the file `utils.py` gives the following probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -13.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-e0ec8ea46ac6>:21: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(Pprod)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       -inf\n",
      "       -inf\n"
     ]
    }
   ],
   "source": [
    "print(f\"{logp(utils.X1, utils.m1, utils.S1):11.4f}\")\n",
    "print(f\"{logp(utils.X2, utils.m2, utils.S2):11.4f}\")\n",
    "print(f\"{logp(utils.X3, utils.m3, utils.S3):11.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is numerically unstable for multiple reasons. The product of many probabilities, the inversion of a large covariance matrix, and the computation of its determinant, are all potential causes for overflow. Thus, we would like to find a numerically robust way of performing each of these.\n",
    "\n",
    "* Implement a numerically stable version of the function `logp`\n",
    "* Evaluate it on the same datasets and parameters as the function `logp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b646a75ea0a26c433a260b8423942ad5",
     "grade": false,
     "grade_id": "cell-a020bd733a8339e3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def logp_robust(X, m, S):\n",
    "    \"\"\"\n",
    "    Numerically robust implemenation of `logp` function\n",
    "    \n",
    "    Returns:\n",
    "        (float): The logp probability density\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    d = X.shape[1]\n",
    "    N = X.shape[0]\n",
    "\n",
    "    \n",
    "#invert the covariance matrix\n",
    "\n",
    "    inv_S =np.linalg.inv(S)\n",
    "    Dbar = X- m\n",
    "    A = np.linalg.solve(S, Dbar.T)\n",
    "    \n",
    "    #                                                                             #19.satir  sonra 16.satirin en solu\n",
    "    logp = -0.5 * ((N * d *np.log(2*np.pi)) + (N * np.log(np.linalg.det(S)) + np.trace(np.dot(Dbar,A))))\n",
    "    \n",
    "    return logp\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1c4ffdd340b15eb149fd295e7cfac7e",
     "grade": true,
     "grade_id": "cell-4f1273a1bd8fc128",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -13.0068\n",
      " -1947.9710\n",
      "-218646.1739\n",
      "\n",
      "all logp values below zero 😀\n"
     ]
    }
   ],
   "source": [
    "# Verify your function\n",
    "logp1 = logp_robust(utils.X1, utils.m1, utils.S1)\n",
    "logp2 = logp_robust(utils.X2, utils.m2, utils.S2)\n",
    "logp3 = logp_robust(utils.X3, utils.m3, utils.S3)\n",
    "\n",
    "print(f\"{logp1:11.4f}\")\n",
    "print(f\"{logp2:11.4f}\")\n",
    "print(f\"{logp3:11.4f}\")\n",
    "\n",
    "\n",
    "outputs = np.array((logp1, logp2, logp3))\n",
    "t.assertTrue(np.isfinite(outputs).all())\n",
    "t.assertTrue(np.all(outputs < 0))\n",
    "print(\"\\nall logp values below zero 😀\")\n",
    "\n",
    "t.assertAlmostEqual(logp(utils.X1, utils.m1, utils.S1), logp1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
